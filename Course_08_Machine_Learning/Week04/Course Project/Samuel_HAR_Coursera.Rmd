---
title: "HAR Coursera John´s Hopkins Pratical ML"
author: "Samuel Bozzi Baco"
output: html_notebook
---
## 0. PACKAGE LOAD AND MARKDOWN CONFIGURATION

```{r PACKAGE LOAD, echo=T, message=F, warning=F}
library(tidyverse)
library(caret)
library(future)
library(doParallel)
```
## 1. DATA DOWNLOAD

The data will be downloaded using the link from Coursera page.
```{r DATA DOWNLOAD, cache = TRUE}
fileLinkTraining <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv" 

fileLinkTest <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"

harTraining <- read.csv(fileLinkTraining)

harTest <- read.csv(fileLinkTest)
```
## 2. DATA WRANGLING

First columns from both dataset (user name, time stamps) will be remove since the model shall be independent from the person who uses it and it is not a time series. Data on test set has several empty columns and “pure NA´s” columns. This ones will be removed from both training set. Columns with no variation at test set will also be removed.

```{r COLUMN SELECTION}
not_all_na <- function(x) any(!is.na(x)) # function to determine if the column has all values like NA´s

harTstClean <-
        harTest %>%
        select(-c("X", 
                  "user_name", 
                  "raw_timestamp_part_1", 
                  "raw_timestamp_part_2", 
                  "cvtd_timestamp",
                  "problem_id",
                  "num_window")) %>%
        select_if(not_all_na) %>%
        select_if(~n_distinct(.) > 1)

harTrnClean <- harTraining[ ,c(names(harTstClean), "classe")]
```
The training dataset will be split to allow model test and validation at a proportion to 60/20/20 %. 
```{r DATASET SPLIT}
inVal = createDataPartition(harTrnClean$classe, p = 0.2, list = F)

val <- harTrnClean[inVal, ]

model <- harTrnClean[-inVal, ]

inTrain <- createDataPartition(model$classe, p = (0.6/0.8), list = F)

train <- model[inTrain, ]

test <- model[-inTrain, ]
```
## 3. EDA

Pre-model tasks are related evaluate the Null Model predictions. This will be accomplished considering the most frequent class in all “predictions”, generating a lower limit for any model that will be created, as suggest by Zumel and Mount (2014). 

### 3.1 Null model performance

```{r NULL MODEL PERFORMANCE, message=F, warning=F}
nullPred <- test %>% select("classe")

nullPred$pred.class <- names(sort(table(nullPred$classe), decreasing = TRUE)[1])

print(confusionMatrix(as.factor(nullPred$pred.class), reference = as.factor(nullPred$classe)))
```



## 4. MODELING

## 5. FINAL MODEL EVALUATION